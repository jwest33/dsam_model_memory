# Core dependencies
numpy>=1.21.0
requests>=2.28.0
psutil>=5.9.0

# LLM server dependencies (already have llama_server_client.py)
# The llama.cpp server should be installed separately via:
# winget install ggml.llamacpp (Windows)
# or build from source: https://github.com/ggerganov/llama.cpp

# Embedding and ML (optional but recommended)
sentence-transformers>=2.2.0
torch>=2.0.0  # Required by sentence-transformers

# Vector storage (optional but recommended)
chromadb>=0.4.0

# Clustering and analysis
hdbscan>=0.8.0
scikit-learn>=1.0.0
matplotlib>=3.5.0
seaborn>=0.11.0

# Development dependencies (optional)
pytest>=7.0.0
black>=22.0.0
mypy>=1.0.0

# Additional utilities
python-dotenv>=1.0.0  # For environment variable management

# Web interface dependencies
flask>=2.3.0
flask-cors>=4.0.0  # For CORS support if needed
